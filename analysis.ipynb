{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('data/SMID_norms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all columns\n",
    "cols = data.columns\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_cols = ['img_name', 'moral_mean', 'moral_sd', 'moral_se', 'moral_n', 'prop_immoral', 'prop_moral', 'prop_neutral']\n",
    "moral_data = data[moral_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add is_moral column, if max of ('prop_immoral', 'prop_moral', 'prop_neutral') is 'prop_moral' set it to 1\n",
    "# if max of ('prop_immoral', 'prop_moral', 'prop_neutral') is 'prop_immoral' set it to -1\n",
    "# if max of ('prop_immoral', 'prop_moral', 'prop_neutral') is 'prop_neutral' set it to 0\n",
    "moral_data.loc[:, 'is_moral'] = moral_data[['prop_immoral', 'prop_moral', 'prop_neutral']].idxmax(axis=1).apply(lambda x: 1 if x == 'prop_moral' else -1 if x == 'prop_immoral' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses_llava.csv\n",
    "# responses = pd.read_csv('data/kosmos_to_llama_250.csv')\n",
    "responses = pd.read_csv('data/responses_llava.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_integer_in_string(s):\n",
    "    numbers = re.findall(r'\\b\\d+\\b', s)\n",
    "    return int(numbers[0]) if numbers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast responses['generated_text_two'] to int into a new column called llm_rating, save the indices of the rows that fail to cast as int\n",
    "failed_cast = []\n",
    "for i, x in enumerate(responses['llama_ratings']):\n",
    "    try:\n",
    "        responses.loc[i, 'llm_ratings'] = int(x)\n",
    "    except ValueError:\n",
    "        failed_cast.append(i)\n",
    "        # find the integer in the first sentence of the response\n",
    "        try:\n",
    "            first_sentence = x.split('.')[0]\n",
    "            responses.loc[i, 'llm_ratings'] = find_integer_in_string(first_sentence)\n",
    "        except ValueError:\n",
    "            responses.loc[i, 'llm_ratings'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['llama_ratings'].iloc[failed_cast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in failed_cast:\n",
    "    print(responses.loc[i, 'llama_ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any NaN values in llm_rating\n",
    "responses['llm_ratings'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add is_moral_llm column to responses dataframe, if generated_text_two is > 3 set it to 1, if generated_text_two is < 3 set it to -1, if generated_text_two is 3 set it to 0\n",
    "responses.loc[:, 'is_moral_llm'] = responses['llm_ratings'].apply(lambda x: 1 if x > 3 else -1 if x < 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast responses['generated_text_three] to int into a new column called vlm_rating, save the indices of the rows that fail to cast as int\n",
    "failed_cast = []\n",
    "for i, x in enumerate(responses['generated_text_three']):\n",
    "    try:\n",
    "        responses.loc[i, 'vlm_rating'] = int(x)\n",
    "    except ValueError:\n",
    "        failed_cast.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add is_moral_vlm column to responses dataframe, if vlm_rating is > 3 set it to 1, if vlm_rating is < 3 set it to -1, if vlm_rating is 3 set it to 0\n",
    "responses.loc[:, 'is_moral_vlm'] = responses['vlm_rating'].apply(lambda x: 1 if x > 3 else -1 if x < 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find immoral responses\n",
    "immoral_responses = responses[responses['is_moral_llm'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_responses = responses[responses['is_moral_vlm'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data['is_moral'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses['is_moral_llm'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data/img/ from image names in responses dataframe\n",
    "responses['image_names'] = responses['image_names'].apply(lambda x: x.replace('data/img/', ''))\n",
    "\n",
    "# remove suffix (.jpg, ...) from image names in responses dataframe\n",
    "responses['image_names'] = responses['image_names'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data.loc[moral_data['img_name'] == 'b999_p491_9', 'is_moral'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want two things:\n",
    "# (1) Percent Correct: This one shows how often the model's moral judgment matches the majority of the human participants' moral judgments, and\n",
    "# (2) a root-mean-square error (RMSE) plot, which indicates the RMSE between the model's moral judgement and the average score reported by the human participants. \n",
    "\n",
    "# (1) Percent Correct\n",
    "# moral_data['is_moral'] is the majority human judgment\n",
    "# responses['is_moral_llm'] is the llm model judgment\n",
    "# responses['is_moral_vlm'] is the vlm model judgment\n",
    "\n",
    "# moral_data['img_name] is the image name\n",
    "# responses['image_names'] is the image name\n",
    "\n",
    "# calculate the number of correct moral judgments for llm model for all images\n",
    "correct_llm = 0\n",
    "for i, x in enumerate(responses['image_names']):\n",
    "    if moral_data.loc[moral_data['img_name'] == x, 'is_moral'].values[0] == responses.loc[i, 'is_moral_llm']:\n",
    "        correct_llm += 1\n",
    "\n",
    "total_llm = len(responses['is_moral_llm'])\n",
    "percent_correct_llm = correct_llm / total_llm * 100\n",
    "percent_correct_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of correct moral judgments for vlm model for all images\n",
    "correct_vlm = 0\n",
    "for i, x in enumerate(responses['image_names']):\n",
    "    if moral_data.loc[moral_data['img_name'] == x, 'is_moral'].values[0] == responses.loc[i, 'is_moral_vlm']:\n",
    "        correct_vlm += 1\n",
    "\n",
    "total_vlm = len(responses['is_moral_vlm'])\n",
    "percent_correct_vlm = correct_vlm / total_vlm * 100\n",
    "percent_correct_vlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = moral_data.loc[moral_data['img_name'].isin(responses['image_names']), 'img_name']\n",
    "right = responses.loc[responses['image_names'].isin(moral_data['img_name']), 'image_names']\n",
    "\n",
    "assert left.isin(right).all() and right.isin(left).all(), \"The 'img_name' in moral_data and 'image_names' in responses do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) RMSE\n",
    "# moral_data['moral_mean'] is the average score reported by the human participants\n",
    "# responses['llm_rating'] is the llm model judgment\n",
    "# responses['vlm_rating'] is the vlm model judgment\n",
    "\n",
    "# moral_data['img_name] is the image name\n",
    "# responses['image_names'] is the image name\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# calculate the RMSE between the llm model judgment and the average score reported by the human participants for all matching images\n",
    "merged_data = pd.merge(moral_data, responses, left_on='img_name', right_on='image_names')\n",
    "llm_mse = mean_squared_error(merged_data['moral_mean'], merged_data['llm_ratings'])\n",
    "llm_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_rmse = np.sqrt(llm_mse)\n",
    "llm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm_mse = mean_squared_error(merged_data['moral_mean'], merged_data['vlm_rating'])\n",
    "vlm_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlm_rmse = np.sqrt(vlm_mse)\n",
    "vlm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all rows where moral_data['is_moral'] == -1\n",
    "immoral_data = moral_data[moral_data['is_moral'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the the rows where prop_immoral is the above 0.8\n",
    "immoral_data = immoral_data[immoral_data['prop_immoral'] > 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immoral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#responses['is_moral_llm'] is the llm model judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos_raw = pd.read_csv('data/results_kosmos-2-patch14-224.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kosmos_raw['generated_text_three'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
